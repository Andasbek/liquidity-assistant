# # --- LLM CONFIG ---
# LLM_PROVIDER=ollama            # ollama | openai | (пусто = без LLM)
# LLM_MODEL=llama3.1             # для ollama: например llama3.1 / mistral / qwen2
# OLLAMA_BASE_URL=http://host.docker.internal:11434

# # Для OpenAI-совместимого API (vLLM/иное):
# # LLM_PROVIDER=openai
# # OPENAI_BASE_URL=http://your-vllm-host:8001/v1
# # OPENAI_API_KEY=your_token

# LLM
LLM_PROVIDER=ollama
LLM_MODEL=mistral:latest
OLLAMA_BASE_URL=http://127.0.0.1:11434

# Scheduler
SYNC_EVERY_MIN=60

# FX
FX_PAIRS=USD/KZT,EUR/KZT
